{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDCTA\n",
    "# San Diego County Homelessness Program Analysis Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To quickly install all req, uncomment line of code below (Note: Only run once!)\n",
    "#!pip install -r requirements.txt\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique.ID</th>\n",
       "      <th>Grantor</th>\n",
       "      <th>Grantee</th>\n",
       "      <th>Program</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Amount</th>\n",
       "      <th>AmendmentNumber</th>\n",
       "      <th>Funding.Agency</th>\n",
       "      <th>...</th>\n",
       "      <th>Issued</th>\n",
       "      <th>Funding.Type</th>\n",
       "      <th>Years</th>\n",
       "      <th>Average.By.Year</th>\n",
       "      <th>City.Year</th>\n",
       "      <th>Population</th>\n",
       "      <th>Amount.Per.Capita</th>\n",
       "      <th>Amount.Per.PEH</th>\n",
       "      <th>Population.PEH</th>\n",
       "      <th>ExpenditureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach|2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Other/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach|2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Other/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach|2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Other/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach|2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Other/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City of Imperial Beach|2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Other/Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unique.ID                 Grantor Grantee Program    Year Date EndDate  \\\n",
       "0       NaN  City of Imperial Beach     NaN     NaN  2022.0  NaN     NaN   \n",
       "1       NaN  City of Imperial Beach     NaN     NaN  2021.0  NaN     NaN   \n",
       "2       NaN  City of Imperial Beach     NaN     NaN  2020.0  NaN     NaN   \n",
       "3       NaN  City of Imperial Beach     NaN     NaN  2019.0  NaN     NaN   \n",
       "4       NaN  City of Imperial Beach     NaN     NaN  2018.0  NaN     NaN   \n",
       "\n",
       "  Amount AmendmentNumber Funding.Agency  ... Issued Funding.Type Years  \\\n",
       "0      0             NaN            NaN  ...    NaN          NaN   NaN   \n",
       "1      0             NaN            NaN  ...    NaN          NaN   NaN   \n",
       "2      0             NaN            NaN  ...    NaN          NaN   NaN   \n",
       "3      0             NaN            NaN  ...    NaN          NaN   NaN   \n",
       "4      0             NaN            NaN  ...    NaN          NaN   NaN   \n",
       "\n",
       "  Average.By.Year                    City.Year  Population Amount.Per.Capita  \\\n",
       "0             NaN  City of Imperial Beach|2022         NaN            $0.00    \n",
       "1             NaN  City of Imperial Beach|2021         NaN            $0.00    \n",
       "2             NaN  City of Imperial Beach|2020         NaN            $0.00    \n",
       "3             NaN  City of Imperial Beach|2019         NaN            $0.00    \n",
       "4             NaN  City of Imperial Beach|2018         NaN            $0.00    \n",
       "\n",
       "  Amount.Per.PEH  Population.PEH ExpenditureType  \n",
       "0         $0.00              0.0   Other/Unknown  \n",
       "1         $0.00              0.0   Other/Unknown  \n",
       "2         $0.00             16.0   Other/Unknown  \n",
       "3         $0.00             12.0   Other/Unknown  \n",
       "4         $0.00              7.0   Other/Unknown  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data\n",
    "raw = pd.read_csv(\"data/raw/CityExpendituresRaw.csv\")\n",
    "raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Filtering\n",
    "Since the goal is to filter the unique programs down as small as possible with the intention of combinining programs that do the same thing, but named slightly differently, checking if any of the `Program` row strings contain the name of another program could yield some level of shrinkage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_42060\\3203349683.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique program names in raw data: 186\n",
      "Unique program names in processed data: 107\n"
     ]
    }
   ],
   "source": [
    "# Function to update program names by checking for occurrences in the 'Program' column\n",
    "def update_program_column(processed):\n",
    "    \"\"\"\n",
    "    Update program names by checking if other rows contain the same string.\n",
    "\n",
    "    Parameters:\n",
    "    - processed: The DataFrame containing the 'Program' column.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with updated program names.\n",
    "    \"\"\"\n",
    "    # Create a mapping of unique program values\n",
    "    program_mapping = {val: val for val in processed['Program'].dropna().unique()}\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in processed.iterrows():\n",
    "        program = row['Program']\n",
    "        # Check if the program is a string\n",
    "        if isinstance(program, str):\n",
    "            # Update other occurrences of the program name\n",
    "            processed.loc[processed['Program'].str.contains(program, na=False), 'Program'] = program_mapping[program]\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "# Function to replace dashes with spaces in the 'Program' column\n",
    "def replace_dashes_with_spaces(processed):\n",
    "    \"\"\"\n",
    "    Replace all dashes in the 'Program' column with spaces.\n",
    "\n",
    "    Parameters:\n",
    "    - processed: The DataFrame containing the 'Program' column.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with the dashes replaced by spaces.\n",
    "    \"\"\"\n",
    "    # Replace dashes with spaces in the 'Program' column\n",
    "    processed['Program'] = processed['Program'].str.replace('-', ' ', regex=False)\n",
    "\n",
    "    return processed\n",
    "\n",
    "# Create copy of raw data frame for data cleaing\n",
    "processed = raw.copy()\n",
    "\n",
    "# Convert all program names to lowercase for standardization\n",
    "processed['Program'] = processed['Program'].str.lower()\n",
    "\n",
    "# Replace dashes with spaces in the 'Program' column\n",
    "processed = replace_dashes_with_spaces(processed)\n",
    "\n",
    "# Update program names based on occurrences in the DataFrame\n",
    "processed = update_program_column(processed)\n",
    "\n",
    "# Display the number of unique program names before and after processing\n",
    "print(\"Unique program names in raw data:\", len(raw[\"Program\"].unique()))\n",
    "print(\"Unique program names in processed data:\", len(processed['Program'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach yielded pretty good results. Will try manual cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'rental assistance' 'homeless services' 'shelter' 'motel voucher'\n",
      " 'rapid re housing' 'project h.o.p.e.' 'take back the streets'\n",
      " 'work for hope' 'housing navigator' 'improve fencing' 'hvac replacements'\n",
      " 'acquisition of facilility for provision of homeless'\n",
      " 'railing replacement' 'security fencing' 'outreach' 'scattered site'\n",
      " 'supportive service  a way back home'\n",
      " 'general funding for homelessness services' 'housing stability services'\n",
      " 'housing navigation services' 'hygiene supplies' 'gift cards'\n",
      " 'city housing support' 'fair housing' 'program development'\n",
      " '211 assistance' 'case management'\n",
      " 'provide emergency housing to imminently homeless, or episodically and chronically homeless individuals and families in the city of santee, and who are unable to access housing during the coronavirus pandemic'\n",
      " 'provide support for regional homeless service providers, networking and communication for organizations serving and impacted by homeless persons, and building capacity of the east county homeless task force'\n",
      " 'provide services to families, abused youth, seniors and veterans experiencing homelessness and domestic violence with housing and wrap around services.'\n",
      " 'point in time count' 'outreeach' 'consulting services homeless'\n",
      " 'communities in action']\n"
     ]
    }
   ],
   "source": [
    "print(processed['Program'].unique()[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_program_value(processed, value_to_convert, new_value):\n",
    "    \"\"\"\n",
    "    Convert a specified value in the 'Program' column of the processed DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - processed: The DataFrame containing the 'Program' column.\n",
    "    - value_to_convert: The value in the 'Program' column that you want to convert.\n",
    "    - new_value: The new value to replace the old value with.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with the specified conversion applied.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace the specified value in the 'Program' column\n",
    "    processed['Program'] = processed['Program'].replace(value_to_convert, new_value)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique program names in processed data: 105\n"
     ]
    }
   ],
   "source": [
    "processed = convert_program_value(processed,\n",
    "                                    'address homeless issues through case management; provide food, shelter vouchers, as well as skill development for long-term self-sufficiency to 200 residents.',  \n",
    "                                   'address homeless issues through case management, provide food, shelter vouchers, and skill development for long-term self sufficiency'\n",
    ")\n",
    "\n",
    "processed = convert_program_value(processed,\n",
    "                                  'outreeach',\n",
    "                                  'outreach'\n",
    ")\n",
    "print(\"Unique program names in processed data:\", processed['Program'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Cleaning was horrible. Going to try more advanced techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique program names after clustering: 105\n",
      "Program changes mapping: {}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def cluster_programs_with_mapping(processed):\n",
    "    \"\"\"\n",
    "    Cluster similar program names and create a mapping of original to representative names.\n",
    "\n",
    "    Parameters:\n",
    "    - processed: DataFrame containing the 'Program' column.\n",
    "\n",
    "    Returns:\n",
    "    - processed: Same DataFrame with updated program names.\n",
    "    - change_mapping: A dictionary mapping original program names to their representative names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract unique program names while dropping NA values\n",
    "    unique_programs = processed['Program'].dropna().unique().tolist()\n",
    "\n",
    "    # Convert the program names into a TF-IDF matrix for clustering\n",
    "    vectorizer = TfidfVectorizer().fit_transform(unique_programs)\n",
    "    vectors = vectorizer.toarray()\n",
    "\n",
    "    # Perform hierarchical clustering on the TF-IDF vectors\n",
    "    clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=0.5)  # Adjust threshold as necessary\n",
    "    clustering_model.fit(vectors)\n",
    "\n",
    "    # Create a mapping of clusters to program names and track changes\n",
    "    cluster_mapping = {}\n",
    "    change_mapping = {}\n",
    "\n",
    "    # Iterate over each unique cluster\n",
    "    for cluster in set(clustering_model.labels_):\n",
    "        # Get all program names in the current cluster\n",
    "        cluster_programs = [unique_programs[i] for i in range(len(unique_programs)) if clustering_model.labels_[i] == cluster]\n",
    "        representative_program = cluster_programs[0]  # Use the first program in the cluster as the representative\n",
    "\n",
    "        # Map each program in the cluster to the representative program\n",
    "        for program in cluster_programs:\n",
    "            cluster_mapping[program] = representative_program\n",
    "            if program != representative_program:\n",
    "                change_mapping[program] = representative_program  # Record the change\n",
    "\n",
    "    # Replace program values in the processed DataFrame with their representatives\n",
    "    processed['Program'] = processed['Program'].replace(cluster_mapping)\n",
    "\n",
    "    return processed, change_mapping\n",
    "\n",
    "\n",
    "# Apply Cluster Cleaning\n",
    "processed, changes = cluster_programs_with_mapping(processed)\n",
    "\n",
    "# Display the number of unique program names in the processed DataFrame\n",
    "print(\"Unique program names after clustering:\", processed['Program'].nunique())\n",
    "# Show what each program was changed from and to\n",
    "print(\"Program changes mapping:\", changes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluter method didn't detect anything to change. Going to save `processed` data frame for as is for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data\\processed\\processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the 'data/processed' directory if it doesn't exist\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join('data', 'processed', 'processed.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "processed.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the preparation of this work the author used ChatGPT in order to streamline the creation of the functions. After using this tool, the author identified and reviewed the content as needed and takes full responsibility for the content of the code and resulting processed data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDCTA-SD-HPA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
